{"cells":[{"cell_type":"markdown","source":["### Training of Model with encoder as ALBERT(base) along the internal answerability verifier"],"metadata":{"id":"mSKg8btASedE"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"Fxo8pqrgJUti"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1n4nrhTp5rw"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","import pandas as pd\n","import transformers\n","from transformers import AlbertTokenizerFast\n","from transformers import AlbertModel, AlbertConfig, AlbertPreTrainedModel\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dGV5nqML0TOB","outputId":"e716e3f4-94c4-4a23-9008-e6fe746bab88"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Theme</th>\n","      <th>Paragraph</th>\n","      <th>Question</th>\n","      <th>Answer_possible</th>\n","      <th>Answer_text</th>\n","      <th>Answer_start</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>When did Beyonce leave Destiny's Child and bec...</td>\n","      <td>True</td>\n","      <td>['2003']</td>\n","      <td>[526]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>What album made her a worldwide known artist?</td>\n","      <td>True</td>\n","      <td>['Dangerously in Love']</td>\n","      <td>[505]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>Who managed the Destiny's Child group?</td>\n","      <td>True</td>\n","      <td>['Mathew Knowles']</td>\n","      <td>[360]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>When did Beyoncé rise to fame?</td>\n","      <td>True</td>\n","      <td>['late 1990s']</td>\n","      <td>[276]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>What role did Beyoncé have in Destiny's Child?</td>\n","      <td>True</td>\n","      <td>['lead singer']</td>\n","      <td>[290]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Theme                                          Paragraph  \\\n","0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","1  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","3  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","4  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","\n","                                            Question  Answer_possible  \\\n","0  When did Beyonce leave Destiny's Child and bec...             True   \n","1      What album made her a worldwide known artist?             True   \n","2             Who managed the Destiny's Child group?             True   \n","3                     When did Beyoncé rise to fame?             True   \n","4     What role did Beyoncé have in Destiny's Child?             True   \n","\n","               Answer_text Answer_start  \n","0                 ['2003']        [526]  \n","1  ['Dangerously in Love']        [505]  \n","2       ['Mathew Knowles']        [360]  \n","3           ['late 1990s']        [276]  \n","4          ['lead singer']        [290]  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"train_data.csv\")\n","df.drop(\"Unnamed: 0\",axis=1, inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"wpF0Malcadlg","outputId":"785db26e-419e-4645-b3ae-8cd4feca4ae4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Theme</th>\n","      <th>Paragraph</th>\n","      <th>Question</th>\n","      <th>Answer_possible</th>\n","      <th>Answer_text</th>\n","      <th>Answer_start</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>When did Beyonce leave Destiny's Child and bec...</td>\n","      <td>True</td>\n","      <td>2003</td>\n","      <td>526</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>What album made her a worldwide known artist?</td>\n","      <td>True</td>\n","      <td>Dangerously in Love</td>\n","      <td>505</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>Who managed the Destiny's Child group?</td>\n","      <td>True</td>\n","      <td>Mathew Knowles</td>\n","      <td>360</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>When did Beyoncé rise to fame?</td>\n","      <td>True</td>\n","      <td>late 1990s</td>\n","      <td>276</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>What role did Beyoncé have in Destiny's Child?</td>\n","      <td>True</td>\n","      <td>lead singer</td>\n","      <td>290</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Theme                                          Paragraph  \\\n","0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","1  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","3  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","4  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","\n","                                            Question  Answer_possible  \\\n","0  When did Beyonce leave Destiny's Child and bec...             True   \n","1      What album made her a worldwide known artist?             True   \n","2             Who managed the Destiny's Child group?             True   \n","3                     When did Beyoncé rise to fame?             True   \n","4     What role did Beyoncé have in Destiny's Child?             True   \n","\n","           Answer_text Answer_start  \n","0                 2003          526  \n","1  Dangerously in Love          505  \n","2       Mathew Knowles          360  \n","3           late 1990s          276  \n","4          lead singer          290  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# preprocessing in answer text\n","df['Answer_text'] = df['Answer_text'].apply(lambda x: x.lstrip(\"[\").rstrip(\"]\").strip(\"'\").strip('''\"'''))\n","df['Answer_text'] = df['Answer_text'].apply(lambda x: x.replace(\"\\\\\",\"\"))\n","df['Answer_start'] = df['Answer_start'].apply(lambda x: x.lstrip('[').rstrip(']'))\n","df.iloc[37668, 4] = df.iloc[37668, 4].replace(\"ufeff\", \"\")\n","df.iloc[37668, 1] = df.iloc[37668, 1].replace(\"\\ufeff\", \"\")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"S_rHQbRIdVMq","outputId":"cdc844f9-cbf9-4d1a-e5e5-8d2de7823e8d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Theme</th>\n","      <th>Paragraph</th>\n","      <th>Question</th>\n","      <th>Answer_possible</th>\n","      <th>Answer_text</th>\n","      <th>Answer_start</th>\n","      <th>Answer_end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>When did Beyonce leave Destiny's Child and bec...</td>\n","      <td>True</td>\n","      <td>2003</td>\n","      <td>526</td>\n","      <td>530</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>What album made her a worldwide known artist?</td>\n","      <td>True</td>\n","      <td>Dangerously in Love</td>\n","      <td>505</td>\n","      <td>524</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>Who managed the Destiny's Child group?</td>\n","      <td>True</td>\n","      <td>Mathew Knowles</td>\n","      <td>360</td>\n","      <td>374</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>When did Beyoncé rise to fame?</td>\n","      <td>True</td>\n","      <td>late 1990s</td>\n","      <td>276</td>\n","      <td>286</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Beyoncé</td>\n","      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n","      <td>What role did Beyoncé have in Destiny's Child?</td>\n","      <td>True</td>\n","      <td>lead singer</td>\n","      <td>290</td>\n","      <td>301</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Theme                                          Paragraph  \\\n","0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","1  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","2  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","3  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","4  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n","\n","                                            Question  Answer_possible  \\\n","0  When did Beyonce leave Destiny's Child and bec...             True   \n","1      What album made her a worldwide known artist?             True   \n","2             Who managed the Destiny's Child group?             True   \n","3                     When did Beyoncé rise to fame?             True   \n","4     What role did Beyoncé have in Destiny's Child?             True   \n","\n","           Answer_text Answer_start  Answer_end  \n","0                 2003          526         530  \n","1  Dangerously in Love          505         524  \n","2       Mathew Knowles          360         374  \n","3           late 1990s          276         286  \n","4          lead singer          290         301  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# adding end index\n","def add_end_idx(df):\n","  end_idx_list = []\n","  for i in range(len(df)):\n","    gold_text = df.iloc[i, 4]\n","    context = df.iloc[i,1]\n","\n","    if df.iloc[i,3] == True:\n","      start_idx = int(df.iloc[i, 5])\n","      end_idx = start_idx + len(gold_text)\n","      \n","\n","      # sometimes squad answers are off by a character or two so we fix this\n","      if context[start_idx : end_idx] == gold_text:\n","        df.iloc[i, 5] = start_idx\n","        end_idx_list.append(end_idx)\n","      elif context[start_idx - 1:end_idx - 1] == gold_text:\n","        df.iloc[i, 5] = start_idx - 1\n","        end_idx_list.append(end_idx - 1) \n","      elif context[start_idx + 1:end_idx + 1] == gold_text:\n","        df.iloc[i, 5] = start_idx + 1\n","        end_idx_list.append(end_idx + 1)     \n","      elif context[start_idx - 2:end_idx - 2] == gold_text:\n","        df.iloc[i, 5] = start_idx - 2\n","        end_idx_list.append(end_idx - 2)       \n","      elif context[start_idx + 2:end_idx + 2] == gold_text:\n","        df.iloc[i, 5] = start_idx + 2\n","        end_idx_list.append(end_idx + 2)  \n","   \n","      else:\n","        #print(i)\n","        print(context[start_idx:end_idx], gold_text)\n","\n","    else:\n","      df.iloc[i, 5] = 0\n","      end_idx_list.append(0)\n","\n","  df['Answer_end'] = end_idx_list\n","  return df\n","\n","df_preprocessed = add_end_idx(df.copy())\n","df_preprocessed.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"flJWqeza88om"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"CsT2oGoVvooq"},"source":["### Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Yma2MZXvqJo"},"outputs":[],"source":["def normalize_text(s):\n","  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n","  import string, re\n","  def remove_articles(text):\n","    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","    return re.sub(regex, \" \", text)\n","  def white_space_fix(text):\n","    return \" \".join(text.split())\n","  def remove_punc(text):\n","    exclude = set(string.punctuation)\n","    return \"\".join(ch for ch in text if ch not in exclude)\n","  def lower(text):\n","    return text.lower()\n","\n","  return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def exact_match(prediction, truth):\n","    return bool(normalize_text(prediction) == normalize_text(truth))\n","\n","def compute_f1(prediction, truth):\n","  pred_tokens = normalize_text(prediction).split()\n","  truth_tokens = normalize_text(truth).split()\n","  \n","  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","    return int(pred_tokens == truth_tokens)\n","  \n","  common_tokens = set(pred_tokens) & set(truth_tokens)\n","  \n","  # if there are no common tokens then f1 = 0\n","  if len(common_tokens) == 0:\n","    return 0\n","  \n","  prec = len(common_tokens) / len(pred_tokens)\n","  rec = len(common_tokens) / len(truth_tokens)\n","  \n","  return round(2 * (prec * rec) / (prec + rec), 2)\n","\n","\n","\n","def compute_f1_batch(outputs, batch, tokenizer):\n","  answer_start = outputs[1].argmax(dim=1)  \n","  answer_end = outputs[2].argmax(dim=1) \n","\n","  #print(answer_start.size(), answer_end.size())\n","    \n","  truths = [tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input[start:end])) \\\n","                                   for input, start, end in zip(batch['input_ids'].tolist(), batch['start_positions'].tolist(), batch['end_positions'].tolist())]\n","\n","  #print(truths)\n","\n","  predictions = [tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input[start:end])) \\\n","                                   for input, start, end in zip(batch['input_ids'].tolist(), answer_start.tolist(), answer_end.tolist())]\n","\n","  f1_acc = 0\n","  for pred, truth in zip(predictions, truths):\n","    f1_acc += compute_f1(pred, truth)\n","\n","  return round(f1_acc/len(truths), 3)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tmBKYmM9jTSy"},"source":["### Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1H3PmB00TRZ"},"outputs":[],"source":["class CustomDatset(torch.utils.data.Dataset):\n","  def __init__(self, df, tokenizer):\n","    self.data = df\n","    self.tokenizer = tokenizer\n","    \n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def get_answers(self, idx):\n","    answer_text = self.data.loc[idx]['Answer_text']\n","    answer_start = self.data.loc[idx]['Answer_start']\n","    answer_end = self.data.loc[idx]['Answer_end']\n","    is_impossibles = 0.0 if not self.data.loc[idx]['Answer_possible'] else 1.0\n","    return {'text': answer_text, 'answer_start': answer_start, 'answer_end': answer_end, 'is_impossibles':is_impossibles}\n","\n","  def add_token_positions(self, encodings, answers):\n","    start_positions = encodings.char_to_token(answers['answer_start'])\n","    end_positions = encodings.char_to_token(answers['answer_end'])\n","\n","    # if start position is None, the answer passage has been truncated\n","    if start_positions is None:\n","      start_positions = tokenizer.model_max_length\n","\n","    # if end position is None, the 'char_to_token' function points to the space before the correct token - > add + 1\n","    if end_positions is None:\n","      end_positions = encodings.char_to_token(answers['answer_end'] + 1)\n","      \n","    if end_positions is None:\n","      end_positions = encodings.char_to_token(answers['answer_end'] - 1)\n","\n","    if end_positions is None:\n","      end_positions = tokenizer.model_max_length\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions, 'is_impossibles':answers['is_impossibles']})\n","    return encodings\n","\n","  def __getitem__(self, idx):\n","    #print(idx)\n","    contexts = self.data.loc[idx]['Paragraph']\n","    questions = self.data.loc[idx]['Question']\n","    encodings = self.tokenizer(contexts, questions, max_length = 512, truncation=True, padding='max_length')\n","    answers = self.get_answers(idx)\n","    encodings = self.add_token_positions(encodings, answers) \n","    return {key: torch.tensor(val) for key, val in encodings.items()}"]},{"cell_type":"markdown","metadata":{"id":"RMW9cgMtJCXj"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CksibrWeuvzj"},"outputs":[],"source":["class AlbertForQuestionAnswering(AlbertPreTrainedModel):\n","    def __init__(self, config):\n","        super(AlbertForQuestionAnswering, self).__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.albert = AlbertModel(config)\n","        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n","        self.has_ans = nn.Sequential(\n","            nn.Dropout(config.hidden_dropout_prob),\n","            nn.Linear(config.hidden_size, 2)\n","        )\n","\n","        self.init_weights()\n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None,\n","                start_positions=None, end_positions=None, is_impossibles=None):\n","\n","        outputs = self.albert(input_ids,\n","                            attention_mask=attention_mask,\n","                            token_type_ids=token_type_ids,\n","                            position_ids=position_ids,\n","                            head_mask=head_mask,\n","                            inputs_embeds=inputs_embeds)\n","\n","        sequence_output = outputs[0]\n","\n","        logits = self.qa_outputs(sequence_output)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","        # print(start_logits.size())\n","        first_word = sequence_output[:, 0, :]\n","        has_logits = self.has_ans(first_word)\n","        # print(has_logits.size())\n","        if start_positions is not None and end_positions is not None and is_impossibles is not None:\n","            # If we are on multi-GPU, split add a dimension\n","            if len(start_positions.size()) > 1:\n","                start_positions = start_positions.squeeze(-1)\n","            if len(end_positions.size()) > 1:\n","                end_positions = end_positions.squeeze(-1)\n","            if len(is_impossibles.size()) > 1:\n","                is_impossibles = is_impossibles.squeeze(-1)\n","            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n","            ignored_index = start_logits.size(1)\n","            start_positions.clamp_(0, ignored_index)\n","            end_positions.clamp_(0, ignored_index)\n","            is_impossibles.clamp_(0, ignored_index)\n","\n","            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n","            start_loss = loss_fct(start_logits, start_positions)\n","            end_loss = loss_fct(end_logits, end_positions)\n","            span_loss = start_loss + end_loss\n","\n","            # Internal Front Verification (I-FV)\n","            # alpha1 == 1.0, alpha2 == 0.5\n","            choice_loss = loss_fct(has_logits, is_impossibles.long())\n","            total_loss = 1.0 * span_loss + 0.5 * choice_loss\n","\n","\n","\n","            outputs = (start_logits, end_logits, has_logits) + outputs[2:]\n","\n","        return (total_loss,) + outputs  # (loss), start_logits, end_logits, has_logits, (hidden_states), (attentions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCjznPRFm-Hx"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6Ik8tn4Qzrwr"},"source":["### Split data to train and validation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9VaDL3wJGZN","outputId":"219a6ae7-15ce-4fb3-d1d1-846516f4111b"},"outputs":[{"data":{"text/plain":["74680"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# training data as all the theme except Hunting\n","train_df = df_preprocessed[df_preprocessed['Theme'] != 'Hunting']\n","train_df.reset_index(inplace=True)\n","len(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdQD_ciCJuHd","outputId":"5dec2afa-bb8a-4aa0-8fbc-b2e2c494549d"},"outputs":[{"data":{"text/plain":["375"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# validation data as the theme Hunting\n","val_df = df_preprocessed[df_preprocessed['Theme'] == 'Hunting']\n","val_df.reset_index(inplace=True)\n","len(val_df)"]},{"cell_type":"markdown","metadata":{"id":"qZsFkAzVzmw3"},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJLKPk9y0rVv","outputId":"98859559-fda7-445c-8c22-8f72c16bb87c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at albert-base-v1 were not used when initializing AlbertForQuestionAnswering: ['predictions.LayerNorm.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.dense.weight']\n","- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v1 and are newly initialized: ['qa_outputs.weight', 'has_ans.1.bias', 'qa_outputs.bias', 'has_ans.1.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# initializing the model\n","albert_model = 'albert-base-v1'\n","config = AlbertConfig.from_pretrained(albert_model) \n","tokenizer = AlbertTokenizerFast.from_pretrained(albert_model)\n","qa = AlbertForQuestionAnswering(config)\n","model = qa.from_pretrained(albert_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hHjJUIpAv1bK","outputId":"93db46c4-d3ad-4809-fee8-9a98d3acf9ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are working on cuda\n"]}],"source":["# Check on the available device - use GPU\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(f'You are working on {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"_BbLEQ6Pv63g","outputId":"8ddffb42-79eb-4d28-f1f3-b05a5c3ecaf2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1 Training: 100%|████████████████████████████████████████| 9335/9335 [59:58<00:00,  2.59it/s, F1=0.766, loss=3.16]\n","Epoch 1 Validation: 100%|██████████████████████████████████████████| 94/94 [00:06<00:00, 14.18it/s, F1=0.333, loss=3.66]\n"]},{"name":"stdout","output_type":"stream","text":["\n","End of epoch 1|Training Loss: 2.838 F1 Score:   0.617|Validation Loss: 1.919   F1 Score: 0.768\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 Training: 100%|█████████████████████████████████████████| 9335/9335 [1:00:03<00:00,  2.59it/s, F1=1, loss=0.353]\n","Epoch 2 Validation: 100%|██████████████████████████████████████████| 94/94 [00:06<00:00, 14.15it/s, F1=0.667, loss=2.89]\n"]},{"name":"stdout","output_type":"stream","text":["\n","End of epoch 2|Training Loss: 1.978 F1 Score:   0.745|Validation Loss: 1.747   F1 Score: 0.798\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 Training:  91%|█████████████████████████████████████▍   | 8527/9335 [54:48<05:10,  2.60it/s, F1=0.857, loss=1.3]IOPub message rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_msg_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n","Epoch 3 Training: 100%|██████████████████████████████████████| 9335/9335 [1:00:00<00:00,  2.59it/s, F1=0.536, loss=3.91]\n","Epoch 3 Validation: 100%|██████████████████████████████████████████| 94/94 [00:06<00:00, 14.14it/s, F1=0.667, loss=1.99]\n"]},{"name":"stdout","output_type":"stream","text":["\n","End of epoch 3|Training Loss: 1.608 F1 Score:   0.796|Validation Loss: 1.771   F1 Score: 0.788\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 Training: 100%|████████████████████████████████████████| 9335/9335 [59:59<00:00,  2.59it/s, F1=0.805, loss=2.46]\n","Epoch 4 Validation: 100%|█████████████████████████████████████████████| 94/94 [00:06<00:00, 14.16it/s, F1=1, loss=0.632]\n"]},{"name":"stdout","output_type":"stream","text":["\n","End of epoch 4|Training Loss: 1.368 F1 Score:   0.826|Validation Loss: 1.645   F1 Score: 0.821\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5 Training: 100%|█████████████████████████████████████████| 9335/9335 [59:57<00:00,  2.59it/s, F1=0.961, loss=0.8]\n","Epoch 5 Validation: 100%|█████████████████████████████████████████| 94/94 [00:06<00:00, 14.18it/s, F1=0.667, loss=0.767]\n"]},{"name":"stdout","output_type":"stream","text":["\n","End of epoch 5|Training Loss: 1.164 F1 Score:   0.856|Validation Loss: 1.863   F1 Score: 0.783\n"]}],"source":["N_EPOCHS = 5\n","\n","train_data = CustomDatset(train_df, tokenizer)\n","val_data = CustomDatset(val_df, tokenizer)\n","train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n","val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=4)\n","\n","optim = transformers.AdamW(model.parameters(), lr=2e-5, weight_decay = 0.01, no_deprecation_warning=True)\n","\n","# load model if exist, else comment the line\n","# model = torch.load(\"qa_albertEncoder_with_FIV_2.pth\", map_location=device)\n","\n","model.to(device)\n","\n","\n","for epoch in range(N_EPOCHS):\n","  model.train()\n","  loop = tqdm(train_dataloader, leave=True)\n","  \n","  train_loss = []\n","  train_f1 = []\n","  for batch in loop:\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    start_positions = batch['start_positions'].to(device)\n","    end_positions = batch['end_positions'].to(device)\n","    is_impossibles = batch['is_impossibles'].to(device)\n","    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions, is_impossibles=is_impossibles)\n","    loss = outputs[0]\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()\n","\n","    # F1 calculation\n","    f1 = compute_f1_batch(outputs, batch, tokenizer)\n","\n","    train_loss.append(loss)\n","    train_f1.append(f1)\n","\n","    loop.set_description(f'Epoch {epoch+1} Training')\n","    loop.set_postfix(loss=loss.item(), F1=f1)\n","\n","\n","  # saving the model \n","  model_path = f\"qa_albertEncoder_with_FIV_{epoch+1}.pth\"\n","  # torch.save(model, model_path)\n","\n","  # validation\n","  model.eval()\n","  loop = tqdm(val_dataloader, leave=True)\n","  val_f1 = []\n","  val_loss = []\n","  for batch in loop:\n","    with torch.no_grad():\n","      input_ids = batch['input_ids'].to(device)\n","      attention_mask = batch['attention_mask'].to(device)\n","      start_positions = batch['start_positions'].to(device)\n","      end_positions = batch['end_positions'].to(device)\n","      is_impossibles = batch['is_impossibles'].to(device)\n","    \n","      outputs = model(input_ids, \n","                      attention_mask=attention_mask, \n","                      start_positions=start_positions, \n","                      end_positions=end_positions,\n","                      is_impossibles=is_impossibles)\n","        \n","        \n","      loss = outputs[0]\n","      \n","      # F1 calculation\n","      f1 = compute_f1_batch(outputs, batch, tokenizer)\n","\n","      val_loss.append(loss)\n","      val_f1.append(f1)\n","    \n","      \n","\n","      loop.set_description(f'Epoch {epoch+1} Validation')\n","      loop.set_postfix(loss=loss.item(), F1=f1)\n","\n","  print(f'\\nEnd of epoch {epoch+1}|Training Loss: {sum(train_loss)/len(train_loss):.3f} F1 Score: \\\n","  {sum(train_f1)/len(train_f1):.3f}|Validation Loss: {sum(val_loss)/len(val_loss):.3f} \\\n","  F1 Score: {sum(val_f1)/len(val_f1):.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kQgu_L8JTfN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}